---
title: "Main_SRBC"
author: "Pranita Patil, Emily Wefelmeyer, Sridhar Ravula, Igor Pilja"
date: "November 27, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Framework created by Pranita Patil.

##Load libraries
Emily Wefelmeyer
```{r}
if (!require('RCurl')) install.packages('RCurl', quiet=TRUE)
require(Rcurl)

if (!require('dplyr')) install.packages('dplyr', quiet=TRUE)
library(dplyr)

if (!require('Hmisc')) install.packages('Hmisc', quiet=TRUE)
library(Hmisc)

if (!require("stringr")) install.packages("stringr", quiet = TRUE)
library(stringr)

if (!require("lubridate")) install.packages("lubridate", quiet = TRUE)
library(lubridate)

if (!require("rstudioapi")) install.packages("rstudioapi", quiet = TRUE)
library(rstudioapi) 

if (!require('mice')) install.packages('mice', quiet=TRUE)
library(mice)

if (!require('VIM')) install.packages('VIM', quiet=TRUE)
library(VIM)
```

##Import Excel files from Git
###Function
Emily Wefelmeyer
```{r}
importGitHub <- function(url, skip){
  df <- read.csv(text = getURL(url),
                 skip = skip)
  
  return(df)
}
```

###Chemistry Data 
####Load chemistry data
Emily Wefelmeyer
```{r}
source("import_chemistry.R")
chemistry2 <- import_chemistry()
```

###Fish Data 
####Load Fish data
Emily Wefelmeyer
```{r}
source("import_fish.R")
fish <- import_fish()
fishCounts <- fish[[1]]
fishCounts2 <- fish[[2]]
rm(fish)

aggr(fishCounts2,
     col = c("navyblue", 
             "yellow"),
     numbers = TRUE, 
     sortVars = TRUE,
     labels = names(fishCounts2), 
     cex.axis = 0.7,
     gap = 3, 
     ylab = c("Missing Data", "Pattern"), 
     main = "FishCounts")

(list_na <- colnames(fishCounts2)[ apply(fishCounts2, 2, anyNA)])
```
No missing data

###Macro Counts
Emily Wefelmeyer
```{r}
source("import_macro.R")
macroCounts2 <- import_macro()

aggr(macroCounts2,
     col = c("navyblue", 
             "yellow"),
     numbers = TRUE, 
     sortVars = TRUE,
     labels = names(macroCounts2), 
     cex.axis = 0.7,
     gap = 3, 
     ylab = c("Missing Data", "Pattern"), 
     main = "MacroCounts")
```
No missing data

###Attribute data for each site
###Water Quality Measures for entire system
Emily Wefelmeyer
```{r}
source("import_attribute_micro.R")
attribute_micro <- import_attribute_micro()
attributes <- attribute_micro[[1]]
micro <- attribute_micro[[2]]

rm(attribute_micro)

aggr(attributes,
     col = c("navyblue", 
             "yellow"),
     numbers = TRUE, 
     sortVars = TRUE,
     labels = names(attributes), 
     cex.axis = 0.7,
     gap = 3, 
     ylab = c("Missing Data", "Pattern"), 
     main = "Attributes")

(list_na <- colnames(attributes)[ apply(attributes, 2, anyNA)])
```
Missing data not causing issue

### Calculate fish metrics
Emily Wefelmeyer
```{r}
source("Metrics_fish.R")
fishCounts2 <- Metrics_fish(fishCounts, fishCounts2)
```

####Fix TimeDate stamps
Subset dataframes by DTS
```{r}
startDate <- as.numeric(year(max(min(fishCounts2$DateTime), 
                 min(macroCounts2$DateTime))))

startDate <- as.POSIXct(ISOdate(startDate, 01, 01, 0, 0, 0))

endDate <- as.numeric(year(min(max(fishCounts2$DateTime),
               max(macroCounts2$DateTime))))

endDate <- as.POSIXct(ISOdate(endDate, 12, 31, 23, 59, 59))

#DateTime
DateTime <- as.data.frame(seq.POSIXt(startDate, endDate, by = "4 hours"))
colnames(DateTime) <- "DateTime"
```



###Average data over 4 hour period
####Micro data
Sridhar Ravula
```{r}
hourseq = seq.POSIXt(startDate, endDate, by='4 hour')
microt<- micro %>%
   group_by(DateTime = cut(DateTime, breaks=hourseq)) %>%
   summarise_all(mean)  %>% drop_na(DateTime)

microt$DateTime <- as.POSIXct(microt$DateTime, 
                             format = "%Y-%m-%d %H:%M")


micro2 <- merge(DateTime, 
                  microt, 
                  by = "DateTime")
rm(microt, micro)

summary(micro2)
```

####Chemistry data
Sridhar Ravula
```{r}
chemistry2t<- chemistry2 %>%
   group_by(StationID, StationName,DateTime = cut(DateTime, breaks=hourseq)) %>%
   summarise_all(mean)  %>% drop_na(DateTime)

chemistry2t$DateTime <- as.POSIXct(chemistry2t$DateTime, 
                             format = "%Y-%m-%d %H:%M")
chemistry3 <- merge(DateTime,
                    chemistry2t,
                    by = "DateTime")

rm(chemistry2t, chemistry2)

summary(chemistry3)
```
Remove variables with NAs only
```{r}
chemistry3$`BOD5 (mg/l)` <- NULL
chemistry3$`Copper (ug/l)` <- NULL
chemistry3$`Fecal Coliform (#/100ml)` <- NULL
chemistry3$`Fluoride (mg/l)` <- NULL
chemistry3$`Kjeld Nitrogen (mg/l)` <- NULL
chemistry3$`Lead (ug/l)` <- NULL
chemistry3$`Nickel (ug/l)` <- NULL
chemistry3$`Residue (mg/l)` <- NULL
chemistry3$`Zinc (ug/l)` <- NULL
```
####Fish Counts
Emily Wefelmeyer
```{r}
temp <- fishCounts2 %>%
   group_by(StationID, Site.Name, 
            DateTime = cut(DateTime, breaks=hourseq)) %>%
   summarise_all(mean)  %>% drop_na(DateTime)

temp$DateTime <- as.POSIXct(temp$DateTime, 
                             format = "%Y-%m-%d %H:%M")
fishCounts2 <- merge(DateTime,
                    temp,
                    by = "DateTime")
rm(temp)

summary(fishCounts2)
```

####Macro Counts
Emily Wefelmeyer
```{r}
temp <- macroCounts2 %>%
   group_by(Station_ID, Station.Name,
            DateTime = cut(DateTime, breaks=hourseq)) %>%
   summarise_all(mean)  %>% drop_na(DateTime)

temp$DateTime <- as.POSIXct(temp$DateTime, 
                             format = "%Y-%m-%d %H:%M")
macroCounts2 <- merge(DateTime,
                    temp,
                    by = "DateTime")

rm(temp, hourseq)

summary(macroCounts2[,1:100])
summary(macroCounts2[,101:length(macroCounts2)])
```



#Check missing data
Emily Wefelmeyer
```{r}
aggr(chemistry3,
     col = c("navyblue", 
             "yellow"),
     numbers = TRUE, 
     sortVars = TRUE,
     labels = names(chemistry3), 
     cex.axis = 0.7,
     gap = 3, 
     ylab = c("Missing Data", "Pattern"), 
     main = "Chemistry")

chemistry3$CountNA <- apply(chemistry3, MARGIN = 1, function(x) sum(is.na(x)))
chemistry3 <- chemistry3[!(chemistry3$CountNA == 52), ]
chemistry3$CountNA <- NULL
```
Emily Wefelmeyer
```{r}
aggr(micro2,
     col = c("navyblue", 
             "yellow"),
     numbers = TRUE, 
     sortVars = TRUE,
     labels = names(micro2), 
     cex.axis = 0.7,
     gap = 3, 
     ylab = c("Missing Data", "Pattern"), 
     main = "Micro")

micro2$CountNA <- apply(micro2, MARGIN = 1, function(x) sum(is.na(x)))
micro2 <- micro2[!(micro2$CountNA == 5), ]
micro2$CountNA <- NULL
```

####Rename StationIDs for consistency
Emily Wefelmeyer
```{r}
#Rename StationID#s for consistency
macroCounts2$StationID <- macroCounts2$Station_ID
macroCounts2$Station_ID <- NULL

attributes$StationID <- attributes$Station.ID
attributes$Station.ID <- NULL
```

### Combine all Data frames
Emily Wefelmeyer
```{r}
Station = as.numeric(sort(unique(c(chemistry3$StationID, fishCounts2$StationID, macroCounts2$StationID))))

###Combine chemistry, fish count & macro count data
#Create initial data frame from varous pieces
chem <- subset(chemistry3, StationID == Station[1])
fish <- subset(fishCounts2, StationID == Station[1])
macro <- subset(macroCounts2, StationID == Station[1])

#Combine fish & macro counts
temp <- merge(fish,
              macro,
              by = "DateTime",
              all = TRUE)

#Add in chemistry
temp <- merge(chem,
              temp,
              by = "DateTime",
              all = TRUE)

#Clean to have unified station ID
temp$StationID <- rep(Station[1], times = nrow(temp))

#Create initial data frame
allData <- temp
rm(temp)

#Combine rest of the data frames
for(station in Station[2:length(Station)]) {
  chem <- subset(chemistry3, StationID == station)
  fish <- subset(fishCounts2, StationID == station)
  macro <- subset(macroCounts2, StationID == station)
  
  #Combine fish & macro counts
  temp <- merge(fish,
                macro,
                by = "DateTime",
                all = TRUE)
  
  
  #Add chemistry data
  temp <- merge(chem,
                temp,
                by = "DateTime",
                all = TRUE)
  
  #Clean to have unified station ID
  temp$StationID <- rep(station, times = nrow(temp))

  #Add station's data to the full data set
  ifelse(nrow(temp) > 0, 
    (allData[(nrow(allData)+1):(nrow(allData) + nrow(temp)),] <- temp[1:nrow(temp),]),
    allData <- allData)
}

#rename data frame
allData$StationID.x <- NULL
allData$StationID.y <- NULL

rm(chem, fish, macro, temp)


##Add attributes
allData <- merge(allData,
                 attributes,
                 by = "StationID",
                 all = TRUE)

#Prep Micro data
Station <- as.integer(sort(unique(allData$StationID)))
dup <- micro2
StationID <- rep(Station[1], times = nrow(dup))
micro2 <- cbind(dup, StationID)

for (station in Station[2:length(Station)]){
  StationID <- rep(station, times = nrow(dup))
  temp <- cbind(dup, StationID)
  micro2 <- rbind(micro2, temp)
  rm(temp)
}

##Remove unneed variables
rm(dup, Station, station, StationID)

##Combine micro df with fish & macro counts df
allData <- merge(allData,
                 micro2,
                 by = c("DateTime", "StationID"),
                 all.x = TRUE)

hold <- allData

allData$CountNA <- apply(allData, MARGIN = 1, function(x) sum(is.na(x)))
```

```{r}
summary(allData[,1:85])
```

```{r}
summary(allData[,86:171])
```

```{r}
summary(allData[,172:257])
```

```{r}
summary(allData[,258:343])
```

```{r}
summary(allData[,344:length(allData)])
```
```{r}
allData$CountNA <- NULL
```
All of the rows and columns have something in them.


###Variance within variables
Igor Pilja
```{r}
if (!require('assertthat')) install.packages('assertthat', quiet=TRUE)
library(assertthat)
clmnNamesList<-c(colnames(allData))
newList1 <- c()
for (i in 1:(length(allData))) {
  #print(paste('Column name: ',clmnNamesList[i]))
  colNm<-clmnNamesList[i]
  toList<-as.list(allData[i])
  newList <- c()
  count1<-0
  flag<-FALSE
  j<-0
  k<-0
  for (j in toList) {
    for (k in j) {
      if(is.string(k)){
         flag<-TRUE
         #strVal<-'COLUMN HAS STRING VALUES!'
        # print(paste('COLUMN HAS STRING VALUES!'))
         break
       }
      if(!is.na(k)){
       newList[count1]<-k
       count1=count1+1
      }
    }
     if(flag){
       break
     }
    break
  }
  # if(!flag){
  #   print(paste('MEAN: ',mean(newList)))
  #   print(paste('SD: ',sd(newList)))
  #   print(paste('RANGE: ',max(newList)-min(newList)))
  # }
  if(!flag){
    mn<-mean(newList)
    stdv<-sd(newList)
    rng<-max(newList)-min(newList)
    nlst<- cbind(colNm, mn, stdv, rng, min(newList), max(newList))
    newList1<-rbind(newList1,nlst)
    
  }
  if(flag){
    newList1<- newList1
  }
  toList<-c()
}
  colnames(newList1) <- c("Variable",
                          "Mean", 
                          "Standard Deviation", 
                          "Range", 
                          "Minimum", 
                          "Maximum")
  lstToDf<-as.data.frame(newList1)
  write.csv(lstToDf,"VariableVariance.csv")
  plot(allData$WaterTemp, allData$DateTime)
  plot(allData$WaterTemp)
  plot(allData$DateTime, allData$O2Dis)
  plot(allData$O2Dis)
  plot(allData$SpCond, allData$DateTime)
  plot(allData$SpCond)
  plot(allData$Turbidity, allData$DateTime)
  plot(allData$Turbidity)
  plot(allData$pH, allData$DateTime)
  plot(allData$pH)
```

### Calculate Correlaton between FishCount and Fish metrics
Pranita Patil
```{r}
if (!require('ggplot2')) install.packages('ggplot2', quiet=TRUE)
library(ggplot2)
if (!require('reshape2')) install.packages('reshape2', quiet=TRUE)
library(reshape2)


# Calculate Correlation matrix for fish data along with fish metrics
allData3 <- fishCounts2[,-c(1:2, 63)]

corre_ent3 <- rcorr(as.matrix(allData3))

cor_coef3 <- corre_ent3$r
cor_p3 <- corre_ent3$P

# function to visualize correlation matrix
ggheatmap <- function(upper_tri, upper_tri_p, i) 
{
  # Melt the correlation matrix
diag(upper_tri_p) <- Inf
  melted_cormat <- melt(upper_tri)
melted_cormat_p <- melt(upper_tri_p)
melted_cormat_stars <- cut(melted_cormat_p$value, breaks=c(-Inf, 0.001, 0.01, 0.05, Inf), label=c("***", "**", "*", ""))
ggheatmap1 <-ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "red", high = "blue", mid = "white",
                       midpoint = 0, limit = c(-1,1), space = "Lab",
                       name="Pearson\nCorrelation") +
  geom_text(aes(label=melted_cormat_stars), color="black", size=2) +
  geom_tile(data = subset(melted_cormat,  is.na(value)),fill = "white")+
  geom_tile(data = subset(melted_cormat_p,  is.na(value)),fill = "white")+
  theme_minimal()+ # minimal theme
  theme(axis.text.x = element_text(angle = 45, vjust = 1,
                                   size = 9, hjust = 1))+
  coord_fixed()

# Print the heatmap
print(ggheatmap1)
ggsave(ggheatmap1, file=paste0("plot_corr_fish_data", i,".png"), width = 20, height = 20, units = "cm")

}

# Visualize Correlation matrix as whole 
rcoeff <-(cor_coef3)
rpvalue <- (cor_p3)
ggheatmap(rcoeff, rpvalue, 1)

# Visualize above Correlation matrix in two parts for visibility
rcoeff1 <-(cor_coef3[1:30,31:60])
rpvalue1 <- (cor_p3[1:30,31:60])
ggheatmap(rcoeff1, rpvalue1, 2)

rcoeff2 <-(cor_coef3[31:60,31:60])
rpvalue2 <- (cor_p3[31:60,31:60])
ggheatmap(rcoeff2, rpvalue2, 3)

```

### Calculate correlations
Pranita Patil
```{r}
source("Corr_SRBC.R")
corr_results <- Corr_SRBC(allData)

# correlation Coefficients and P values
cor_coef2 <- corr_results[[1]]
cor_p2 <- corr_results[[2]]

# # Use upper triangle of the correlation matrix
# get_upper_tri <- function(cormat){
#   cormat[lower.tri(cormat)]<- NA
#   return(cormat)
# }


k=1
# corplots = list()

for (i in seq(1, 151, by=31))
  for (j in seq(1, 151, by=31))
{
    # get whole correlation matrix
    if(i==125 & j!=125){
    upper_tri <- (cor_coef2[i:(i+26),j:(j+30)])
    upper_tri_p <- (cor_p2[i:(i+26),j:(j+30)])  
    }
    else if(j==125 & i!=125){
      upper_tri <- (cor_coef2[i:(i+30),j:(j+26)])
      upper_tri_p <- (cor_p2[i:(i+30),j:(j+26)]) 
    }
    else if(j==125 & i==125){
      upper_tri <- (cor_coef2[i:(i+26),j:(j+26)])
      upper_tri_p <- (cor_p2[i:(i+26),j:(j+26)]) 
    }
    else{
    upper_tri <- (cor_coef2[i:(i+30),j:(j+30)])
    upper_tri_p <- (cor_p2[i:(i+30),j:(j+30)])
    }
    if(k==1 | k==7 | k==13 | k==19 | k==25 ){
      diag(upper_tri_p) <- Inf
    }
    # Melt the correlation matrix
    melted_cormat <- melt(upper_tri)
    melted_cormat_p <- melt(upper_tri_p)
    melted_cormat_stars <- cut(melted_cormat_p$value, breaks=c(-Inf, 0.001, 0.01, 0.05, Inf), label=c("***", "**", "*", ""))  
    
    # Use ggplot to visualize correlation matrix
    ggheatmap2 <-ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
      geom_tile(color = "white")+
      scale_fill_gradient2(low = "red", high = "blue", mid = "white",
                           midpoint = 0, limit = c(-1,1), space = "Lab",
                           name="Pearson\nCorrelation") +
      geom_text(aes(label=melted_cormat_stars), color="black", size=2) +
      geom_tile(data = subset(melted_cormat,  is.na(value)),fill = "white")+
      geom_tile(data = subset(melted_cormat_p,  is.na(value)),fill = "white")+
      theme_minimal()+ # minimal theme
      theme(axis.text.x = element_text(angle = 45, vjust = 1,
                                       size = 9, hjust = 1))+
      coord_fixed()
    
    # Print the heatmap
    print(ggheatmap2)
    
    # save the heatmap
    ggsave(ggheatmap2, file=paste0("AllData_Corr_plot_", k,".png"), width = 20, height = 20, units = "cm")

 #corplots[[k]] = ggheatmap2
 k=k+1

}

## To save all images in PDF file
# pdf("corr_plots.pdf")
# for (l in 1:25) {
#   print(corplots[[l]])
# }
# dev.off()


rm(rpvalue, rcoeff, allData3, rpvalue1, rcoeff1, rpvalue2, rcoeff2, upper_tri_p, corre_ent3, cor_coef3, cor_p3, cor_coef2, corr_results, cor_p2, ggheatmap2, melted_cormat, melted_cormat_p, melted_cormat_stars, i, j, upper_tri)
```

### Calculate PCA
```{r}
source("PCA_SRBC.R")
PCA_results <- PCA_SRBC()
```

### Build GLM
```{r}
source("GLM_SRBC.R")
GLM_results <- GLM_SRBC()
```

### Build GAM
```{r}
source("GAM_SRBC.R")
GAM_results <- GAM_SRBC()
```

### combining GLM & GAM 
```{r}
source("GLM_GAM_SRBC.R")
GLM_GAM_results <- GLM_GAM_SRBC()
```